{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":65626,"databundleVersionId":8046133,"sourceType":"competition"},{"sourceId":44640,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":37504}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, cross_val_score\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.keras.preprocessing import image","metadata":{"execution":{"iopub.status.busy":"2024-05-07T10:33:14.088563Z","iopub.execute_input":"2024-05-07T10:33:14.089275Z","iopub.status.idle":"2024-05-07T10:33:18.249726Z","shell.execute_reply.started":"2024-05-07T10:33:14.089245Z","shell.execute_reply":"2024-05-07T10:33:18.248705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load our data and do a little cleaning\nplanttraits2024 load \n删除超过前 98% 的数据","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/planttraits2024/train.csv')\ntest = pd.read_csv('/kaggle/input/planttraits2024/test.csv')\n\n# not worring about '_sd' columns for now\nsd_columns = [col for col in train.columns if col.endswith('_sd')]\ntrain = train.drop(columns=sd_columns)\n\n#target columns\nmean_columns = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n\n\nfor column in mean_columns:\n    upper_quantile = train[column].quantile(0.98)  \n    train = train[(train[column] < upper_quantile)]","metadata":{"execution":{"iopub.status.busy":"2024-05-07T10:33:32.838645Z","iopub.execute_input":"2024-05-07T10:33:32.839558Z","iopub.status.idle":"2024-05-07T10:33:34.714268Z","shell.execute_reply.started":"2024-05-07T10:33:32.839525Z","shell.execute_reply":"2024-05-07T10:33:34.713454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load up ImageNet","metadata":{}},{"cell_type":"code","source":"image_model = EfficientNetB3(weights='imagenet', include_top=False, pooling='avg')\n\n#input resolution for the ImageNet\nimage_model_x = 300\nimage_model_y = 300","metadata":{"execution":{"iopub.status.busy":"2024-05-07T10:33:36.773260Z","iopub.execute_input":"2024-05-07T10:33:36.774118Z","iopub.status.idle":"2024-05-07T10:33:38.493414Z","shell.execute_reply.started":"2024-05-07T10:33:36.774084Z","shell.execute_reply":"2024-05-07T10:33:38.492581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions to use EfficientNet to extract image features into tabular data\n## Images are turned into 1280 columns of tabular data!","metadata":{}},{"cell_type":"code","source":"# Define the function to create a TensorFlow dataset for images\ndef create_dataset(image_paths, batch_size=128):\n    def process_path(file_path):\n        img = tf.io.read_file(file_path)\n        img = tf.image.decode_jpeg(img, channels=3)\n        img = tf.image.resize(img, [image_model_x, image_model_y])    #modify this to fit what your ImageNet model expects\n        img = preprocess_input(img)\n        return img\n    path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n    image_ds = path_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n    image_ds = image_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return image_ds\n\ndef extract_features_with_dataset(dataset, df):\n    features_list = []\n    for batch_imgs in dataset:\n        print(\".\", end=\"\")  # Print progress\n        features = image_model.predict(batch_imgs, verbose=0)\n        features_list.extend(features)\n    features_array = np.array(features_list)\n    \n    # Convert the features array into a DataFrame\n    features_df = pd.DataFrame(features_array)\n    \n    features_df.columns = [f'feature_{i}' for i in range(features_array.shape[1])]\n    \n    new_df = pd.concat([df.reset_index(drop=True), features_df.reset_index(drop=True)], axis=1)\n    \n    return new_df","metadata":{"execution":{"iopub.status.busy":"2024-05-07T10:33:40.151510Z","iopub.execute_input":"2024-05-07T10:33:40.151913Z","iopub.status.idle":"2024-05-07T10:33:40.161730Z","shell.execute_reply.started":"2024-05-07T10:33:40.151882Z","shell.execute_reply":"2024-05-07T10:33:40.160565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extract image data for train","metadata":{}},{"cell_type":"code","source":"train_image_folder = '/kaggle/input/planttraits2024/train_images'\n\nimage_paths = [os.path.join(train_image_folder, f\"{img_id}.jpeg\") for img_id in train['id']]\n\n# Create the dataset\nimage_dataset = create_dataset(image_paths)\n\n# Extract features and directly insert them into the DataFrame as separate columns\ntrain = extract_features_with_dataset(image_dataset, train)\n\nprint(train.head())","metadata":{"execution":{"iopub.status.busy":"2024-05-07T10:33:42.069265Z","iopub.execute_input":"2024-05-07T10:33:42.070002Z","iopub.status.idle":"2024-05-07T10:40:07.480027Z","shell.execute_reply.started":"2024-05-07T10:33:42.069967Z","shell.execute_reply":"2024-05-07T10:40:07.479036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross validate / train on tabular data","metadata":{}},{"cell_type":"code","source":"import joblib","metadata":{"execution":{"iopub.status.busy":"2024-05-07T10:40:07.481919Z","iopub.execute_input":"2024-05-07T10:40:07.482238Z","iopub.status.idle":"2024-05-07T10:40:07.487399Z","shell.execute_reply.started":"2024-05-07T10:40:07.482209Z","shell.execute_reply":"2024-05-07T10:40:07.486486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#do cross-validation testing (this is relatively slow)\ndo_cv = True\n\nX_full = train.drop(columns=mean_columns)\nX_full = X_full.loc[:,~X_full.columns.duplicated()]\nY_full = train[mean_columns]\n\n# 모델 불러오기\nloaded_models = {}\nfor column in Y_full.columns:\n    loaded_models[column] = joblib.load(f\"/kaggle/input/x4_mean_model/tensorflow2/x4_mean_model/1/X4_mean_model.pkl\")\n\nmodels = {}\n\nfor column in Y_full.columns:\n    if column in loaded_models:\n        # If the model is loaded, use the loaded model\n        model = loaded_models[column]\n        print(f\"Continuing training for {column}...\")\n    else:\n        # Otherwise, create a new model\n        model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=200, learning_rate=0.05, max_depth=10)\n        print(f\"Training new model for {column}...\")  \n\n    if do_cv: \n        print(f\"\\nDoing cross-validation scoring for {column}...\")\n        scores = cross_val_score(model, X_full, Y_full[column],\n                                 cv=KFold(n_splits=3, shuffle=True, random_state=42),\n                                 scoring='r2')        \n        print(f\"R^2 score for {column}: {np.mean(scores)}\")\n    \n    #train model with all data\n    print(f\"Training model for {column}...\")\n    model.fit(X_full, Y_full[column])\n    models[column] = model\n    \n    # save model\n    for column, model in models.items():\n        joblib.dump(model, f\"{column}_model.pkl\")\n# save model\n    \nfor column, model in models.items():\n    joblib.dump(model, f\"{column}_all_model.pkl\")","metadata":{"execution":{"iopub.status.busy":"2024-05-07T10:41:30.955759Z","iopub.execute_input":"2024-05-07T10:41:30.956145Z","iopub.status.idle":"2024-05-07T15:04:15.200573Z","shell.execute_reply.started":"2024-05-07T10:41:30.956117Z","shell.execute_reply":"2024-05-07T15:04:15.199587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #do cross-validation testing (this is relatively slow)\n# do_cv = True\n\n# X_full = train.drop(columns=mean_columns)\n# X_full = X_full.loc[:,~X_full.columns.duplicated()]\n# Y_full = train[mean_columns]\n\n# models = {}\n\n# for column in Y_full.columns:\n\n#     model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=200, learning_rate=0.05, max_depth=10)\n\n#     if do_cv: \n#         print(f\"\\nDoing cross-validation scoring for {column}...\")\n#         scores = cross_val_score(model, X_full, Y_full[column],\n#                                  cv=KFold(n_splits=3, shuffle=True, random_state=42),\n#                                  scoring='r2')        \n#         print(f\"R^2 score for {column}: {np.mean(scores)}\")\n    \n#     #train model with all data\n#     print(f\"Training model for {column}...\")\n#     model.fit(X_full, Y_full[column])\n#     models[column] = model\n    \n#     # 모델 저장\n#     for column, model in models.items():\n#         joblib.dump(model, f\"{column}_model.pkl\")\n    \n# # # 모델 저장\n# # for column, model in models.items():\n# #     joblib.dump(model, f\"{column}_model.pkl\")","metadata":{"execution":{"iopub.status.busy":"2024-05-07T07:59:18.085155Z","iopub.execute_input":"2024-05-07T07:59:18.085423Z","iopub.status.idle":"2024-05-07T08:51:47.235208Z","shell.execute_reply.started":"2024-05-07T07:59:18.085400Z","shell.execute_reply":"2024-05-07T08:51:47.233644Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models.items()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T08:52:16.882206Z","iopub.execute_input":"2024-05-07T08:52:16.882927Z","iopub.status.idle":"2024-05-07T08:52:16.892869Z","shell.execute_reply.started":"2024-05-07T08:52:16.882897Z","shell.execute_reply":"2024-05-07T08:52:16.891865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip x.zip ./*","metadata":{"execution":{"iopub.status.busy":"2024-05-07T15:11:47.789905Z","iopub.execute_input":"2024-05-07T15:11:47.793565Z","iopub.status.idle":"2024-05-07T15:11:55.608472Z","shell.execute_reply.started":"2024-05-07T15:11:47.793510Z","shell.execute_reply":"2024-05-07T15:11:55.607303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#该代码绘制了每列（column）预测值与实际值之间的散点图。 如果该模型使用多个特征进行预测，则实际值与预测值之间的线性关系将呈现可视化的散点图。import matplotlib.pyplot as plt\n\nfor column in models:\n    model = models[column]\n    predictions = model.predict(X_full)\n\n    plt.figure(figsize=(8, 6)) \n    plt.scatter(Y_full[column], predictions)\n    plt.title(f\"Actual vs Predicted for {column}\")\n    plt.xlabel(\"Actual\")\n    plt.ylabel(\"Predicted\")\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-07T15:12:14.233678Z","iopub.execute_input":"2024-05-07T15:12:14.234510Z","iopub.status.idle":"2024-05-07T15:12:23.127901Z","shell.execute_reply.started":"2024-05-07T15:12:14.234453Z","shell.execute_reply":"2024-05-07T15:12:23.126965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#残差图(residual plot):表示所有预测值与实际值之差的残差用图表示。 这有助于从视觉上把握模型预测好的领域和不准确的领域。for column in models:\n    model = models[column]\n    predictions = model.predict(X_full)\n    residuals = Y_full[column] - predictions\n    plt.figure(figsize=(8, 6))\n    plt.scatter(predictions, residuals)\n    plt.axhline(y=0, color='r', linestyle='-')\n    plt.title(f\"Residual Plot for {column}\")\n    plt.xlabel(\"Predicted values\")\n    plt.ylabel(\"Residuals\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T15:12:29.931321Z","iopub.execute_input":"2024-05-07T15:12:29.932229Z","iopub.status.idle":"2024-05-07T15:12:38.569013Z","shell.execute_reply.started":"2024-05-07T15:12:29.932192Z","shell.execute_reply":"2024-05-07T15:12:38.568050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fill in submit DF with mean of train values by default\n### Provides near-0 R2 score values for any columns we don't predict for\n默认情况下，使用列车值的平均值创建提交DF。\n\n为不可预测的列提供几乎为零的R2评分值。","metadata":{}},{"cell_type":"code","source":"mean_values = Y_full.mean()\nsubmission = pd.DataFrame({'id': test['id']})\nsubmission[Y_full.columns] = mean_values\n\n#rename from _mean\nsubmission.columns = submission.columns.str.replace('_mean', '')\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T15:12:45.268877Z","iopub.execute_input":"2024-05-07T15:12:45.269239Z","iopub.status.idle":"2024-05-07T15:12:45.297466Z","shell.execute_reply.started":"2024-05-07T15:12:45.269212Z","shell.execute_reply":"2024-05-07T15:12:45.296436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extract image data for test","metadata":{}},{"cell_type":"code","source":"test_image_folder = '/kaggle/input/planttraits2024/test_images'\n\nimage_paths = [os.path.join(test_image_folder, f\"{img_id}.jpeg\") for img_id in test['id']]\n\n# Create the dataset\nimage_dataset = create_dataset(image_paths)\n\n# Extract features and directly insert them into the DataFrame as separate columns\ntest = extract_features_with_dataset(image_dataset, test)\n\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T15:12:48.162682Z","iopub.execute_input":"2024-05-07T15:12:48.163882Z","iopub.status.idle":"2024-05-07T15:13:37.003715Z","shell.execute_reply.started":"2024-05-07T15:12:48.163812Z","shell.execute_reply":"2024-05-07T15:13:37.002466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions for test\n## R2 scores look good for all targets - so we predict on everything...","metadata":{}},{"cell_type":"code","source":"submission['X4'] = models['X4_mean'].predict(test)\nsubmission['X11'] = models['X11_mean'].predict(test)\nsubmission['X18'] = models['X18_mean'].predict(test)\nsubmission['X50'] = models['X50_mean'].predict(test)\nsubmission['X26'] = models['X26_mean'].predict(test)\nsubmission['X3112'] = models['X3112_mean'].predict(test)\n\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T15:13:40.544966Z","iopub.execute_input":"2024-05-07T15:13:40.545652Z","iopub.status.idle":"2024-05-07T15:13:42.524775Z","shell.execute_reply.started":"2024-05-07T15:13:40.545615Z","shell.execute_reply":"2024-05-07T15:13:42.523888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit!","metadata":{}},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T15:13:46.926306Z","iopub.execute_input":"2024-05-07T15:13:46.927089Z","iopub.status.idle":"2024-05-07T15:13:46.989282Z","shell.execute_reply.started":"2024-05-07T15:13:46.927055Z","shell.execute_reply":"2024-05-07T15:13:46.988534Z"},"trusted":true},"execution_count":null,"outputs":[]}]}